# MMA_AVEC
MMA动态面部表情识别方法用于AVEC2014子挑战-抑郁程度分数预测
## 设置
### AVEC2014数据集
数据构成：包含 84 名受试者的 300 个视频。受试者需完成指定阅读任务（Northwind）和随意讲述记忆（Freeform）两项任务，每个视频时长在 6 秒到 4 分钟不等。<br>
数据集划分：数据集被分为训练集、开发集和测试集三个部分，每个部分均包含 50 个视频片段。训练集（train)和开发集(dev)用于训练，测试集(test)用于评估模型在抑郁症识别任务上的整体性能。<br>
标签标注：每个视频都有一个抑郁严重程度标签，该标签通过标准化的抑郁问卷 —— 贝克抑郁量表第二版（BDI - II）获取。BDI - II 分数范围从 0 到 63，其中 0 - 13 表示无抑郁，14 - 19 表示轻度抑郁，20 - 28 表示中度抑郁，29 - 63 表示重度抑郁。<br>
### 数据预处理
由于AVEC2014挑战的Baseline使用的均为随意讲述记忆（Freeform)进行训练和测试，为保持一致，本次实验的视频数据也均为Freeform中的视频，共计150个视频。<br>
实验计划采取3种策略：<br>
策略一：使用整个视频，不分割，直接进行预测，使用RMSE和MAE进行评估<br>
策略二：按照沉默时间将视频分割成几个片段，每个片段包含一句话，不使用沉默片段，最终得分由所有分割出的片段的预测结果的平均值/按照时长的加权平均得到，使用RMSE和MAE进行评估<br>
策略三：按照沉默时间将视频分割成几个片段，每个片段包含一句话，考虑到抑郁症病人可能存在语言组织能力不足或者沉默时间较长的情况，因此在模型训练的最终得出回归分数前，初步想法是加上一层，衡量受访者每句话的平均表达时长，沉默时长<br>
## 实验
### 策略一
使用脚本从150个视频中提取音频，得到共150个wav<br>
使用脚本从150个视频中均匀提取N帧，使用MTCNN提取人脸，本实验设置为提取100帧<br> 
train进行训练，dev用于训练过程的评估，test用于最终对best_model的测试与比较<br> 

### 策略二
使用脚本将视频进行分割，存于对应文件夹中<br> 
使用脚本从视频片段提取音频并保存<br> 
使用脚本从视频片段中均匀提取16帧（与MMA-DFER相同设置），并提取人脸<br> 
train:665个视频片段<br> 
dev:437个视频片段<br> 
test:653个视频片段<br> 
train进行训练，dev用于训练过程的评估，test用于最终对best_model的测试与比较<br> 
### 策略三
------暂未实现-----
## 结果
策略一的最好结果----RMSE：9.83----MAE：7.47<br> 
策略二的最好结果----RMSE:RMSE: 8.8970, MAE: 6.7681<br> 
与Baseline对比：<br> 
<img width="918" height="351" alt="image" src="https://github.com/user-attachments/assets/32c3c9fd-12be-43a0-812c-f4922eb178fd" />
